{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯分类器\n",
    "\n",
    "## 朴素贝叶斯\n",
    "\n",
    "在“生成式与判别式”中我们已经知道，生成式学习方法通过贝叶斯公式来转化问题：\n",
    "\n",
    "$$ P\\left(c\\mid \\boldsymbol{x}\\right) = \\frac{P\\left(\\boldsymbol{x}\\mid c\\right)P\\left(c\\right)}{P\\left(\\boldsymbol{x}\\right)} $$\n",
    "\n",
    "而且我们也分析了问题的难点在于类条件概率 $P\\left(\\boldsymbol{x}\\mid c\\right)$ 的求解。为了方便求解，朴素贝叶斯分类器（Naive Bayes classifier）采用了“属性条件独立性假设”（attribute conditional independence assumption）：对已知类别，假设所有属性相互独立。\n",
    "\n",
    "即 $P\\left(\\boldsymbol{x}\\mid c\\right)$ 可以写为：\n",
    "$$\\begin{align*} \n",
    "P(\\boldsymbol{x} \\mid c) &= P(x_1, x_2, \\ldots, x_n \\mid c) \\\\\n",
    "&= P(x_1 \\mid c) P(x_2 \\mid c, x_1) \\ldots P(x_n \\mid c, x_1, \\ldots, x_{n-1}) \\\\\n",
    "&= P(x_1 \\mid c) P(x_2 \\mid c) \\ldots P(x_n \\mid c) \\\\\n",
    "&= \\prod_{i=1}^{n} P(x_i \\mid c)\n",
    "\\end{align*}$$\n",
    "\n",
    "对有所类别来说 $P(\\boldsymbol{x})$ 相同，因此可以得到朴素贝叶斯分类器：\n",
    "\n",
    "$$ h_{nb}(\\boldsymbol{x}) = \\underset{c \\in \\mathcal{Y}}{\\arg \\max} P(c) \\prod_{i=1}^{d} P(x_i \\mid c) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具体计算方法\n",
    "\n",
    "显然，朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率 $P(c)$，并为每个属性估计条件概率 $P(x_i \\mid c)$。\n",
    "\n",
    "令 $D_c$ 表示训练集D中第c类样本组成的集合，若有充足的独立同分布样本，则可容易地估计出类先验概率\n",
    "\n",
    "$$ P(c) = \\frac{\\mid D_c \\mid}{\\mid D \\mid} $$\n",
    "\n",
    "对离散条件而言，令 $D_{c,x_i}$ 表示 $D_c$ 中在第i个属性上取值为 $x_i$ 的样本组成的集合，则条件概率 $P(x_i \\mid c)$ 可估计为\n",
    "\n",
    "$$ P(x_i \\mid c) = \\frac{\\mid D_{c, x_i} \\mid}{\\mid D_c \\mid} $$\n",
    "\n",
    "对连续属性可考虑概率密度函数，假定 $p(x_i \\mid c) \\sim \\mathcal{N}(\\mu_{c,i},\\ \\sigma_{c,i}^2)$，其中 $\\mu_{c,i}$ 和 $\\sigma_{c,i}^2$ 分别是第c类样本在第i个属性上取值的均值和方差，则有\n",
    "\n",
    "$$ p(x_i \\mid c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} \\exp \\left( -\\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拉普拉斯平滑\n",
    "\n",
    "实际中有可能会出现测试集中的 $c$ 和 $x_i$ 在训练集中并没有出现的情况，即有可能 $\\mid D_c \\mid =0$ 或 $\\mid D_{c,x_i} \\mid = 0$。这个情况最大的问题是会导致连乘项整体为0，导致其他类别、其他属性值都被“抹去”。通过拉普拉斯平滑能避免这个问题。\n",
    "\n",
    "具体来说，令N表示训练集D中可能的类别数，$N_i$ 表示第i个属性可能的取值数，则\n",
    "\n",
    "$$ \\begin{align*}\n",
    "\\hat{P}(c) &= \\frac{\\mid D_c \\mid + 1}{\\mid D \\mid +N} \\\\\n",
    "\\hat{P}(x_i \\mid c) &= \\frac{\\mid D_{c, x_i} \\mid + 1}{\\mid D_c \\mid + N_i}\n",
    "\\end{align*}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
