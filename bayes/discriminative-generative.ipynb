{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成式与判别式\n",
    "\n",
    "监督学习的任务就是要学习到一个模型，对于给定一个输入 $\\boldsymbol{x} = \\left[ \\begin{matrix} x_1 & x_2 & \\cdots & x_n \\end{matrix} \\right]^{\\text{T}} $，能够预测其输出 $y$。这个模型一般形式为决策函数：\n",
    "\n",
    "$$ y = h_\\boldsymbol{\\theta}\\left(\\boldsymbol{x}\\right) $$\n",
    "\n",
    "或者条件分布概率：\n",
    "\n",
    "$$ P\\left( c \\mid \\boldsymbol{x} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判别式\n",
    "\n",
    "**判别式学习方法**（discriminative learning algorithms）由数据直接学习到决策函数 $h_\\boldsymbol{\\theta}\\left(\\boldsymbol{x}\\right) $ 或者条件概率 $P\\left(c\\mid\\boldsymbol{x}\\right)$ 分布作为预测的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成式\n",
    "\n",
    "**生成式学习方法**（generative learning algorithms）则是对条件概率 $P\\left(\\boldsymbol{x}\\mid c\\right)$（和概率 $P\\left(c\\right)$）建模，然后依据贝叶斯公式可以计算出给定 $\\boldsymbol{x}$ 下 $c$ 的概率：\n",
    "\n",
    "$$ P\\left(c\\mid \\boldsymbol{x}\\right) = \\frac{P\\left(\\boldsymbol{x}\\mid c\\right)P\\left(c\\right)}{P\\left(\\boldsymbol{x}\\right)} $$\n",
    "\n",
    "其中，$P(c)$ 称为先验（prior）概率；$P(\\boldsymbol{x} \\mid c)$ 是样本 $\\boldsymbol{x}$ 相对于类别c的条件概率，或称为“似然”（likelihood）；$P(\\boldsymbol{x})$ 是用于归一化的“证据”因子。\n",
    "\n",
    "\n",
    "$P\\left( \\boldsymbol{x} \\right)$ 可以求解出来，例如对于二分类问题：\n",
    "\n",
    "$$P\\left(\\boldsymbol{x}\\right) = P\\left(\\boldsymbol{x}\\mid c=1\\right) P\\left(c=1\\right) + P\\left(\\boldsymbol{x}\\mid c=0\\right) P\\left(c=0\\right)$$\n",
    "\n",
    "事实上，对于预测问题，我们可以不用求解出 $P\\left( \\boldsymbol{x} \\right)$：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\underset{c \\in \\mathcal{Y}}{\\arg \\max} P\\left(c \\mid \\boldsymbol{x}\\right) &= \\underset{c \\in \\mathcal{Y}}{\\arg \\max} \\frac{P\\left( \\boldsymbol{x}\\mid c \\right) P\\left( c \\right)} {P\\left( \\boldsymbol{x} \\right)} \\\\ \n",
    "&= \\underset{ c \\in \\mathcal{Y}} {\\arg \\max} P\\left( \\boldsymbol{x}\\mid c \\right) P\\left(c\\right)\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "类先验概率 $P(c)$ 表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$ 可通过各类样本出现的频率来进行估计。\n",
    "\n",
    "对类条件概率 $P(\\boldsymbol{x} \\mid c)$ 来说，由于它涉及关于 $\\boldsymbol{x}$ 所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。例如，假设样本的n个属性都是二值的，则样本空间将有 $2^n$ 种可能的取值，在现实应用中，这个值往往远大于训练样本数m，也就是说，很多样本取值在训练中根本没有出现，直接使用频率来估计 $P(\\boldsymbol{x} \\mid c)$ 显然不行，因为“未被观测到”与“出现概率为零”通常是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特点\n",
    "\n",
    "生成式学习方法特点：\n",
    "\n",
    "- 可以还原出联合概率分布 $p\\left( \\boldsymbol{x}, y \\right) = p\\left( \\boldsymbol{x}\\mid y \\right)p\\left( y \\right)$\n",
    "- 收敛速度更快，当样本容量增加时，学到的模型可以更快地收敛于真实模型\n",
    "- 存在隐变量时，仍然可以用生成式学习方法，此时判别式学习方法就不能用\n",
    "\n",
    "判别式学习方法特点：\n",
    "\n",
    "- 直接面对预测，往往学习的准确率更高\n",
    "- 可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见模型\n",
    "\n",
    "判别式模型常见的主要有：\n",
    "\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Traditional Neural Networks\n",
    "- Nearest Neighbor\n",
    "- CRF\n",
    "- Linear Discriminant Analysis\n",
    "- Boosting\n",
    "- Linear Regression\n",
    "\n",
    "产生式模型常见的主要有：\n",
    "                      \n",
    "- Gaussians\n",
    "- Naive Bayes\n",
    "- Mixtures of Multinomials\n",
    "- Mixtures of Gaussians\n",
    "- Mixtures of Experts\n",
    "- HMMs\n",
    "- Sigmoidal Belief Networks, Bayesian Networks\n",
    "- Markov Random Fields\n",
    "- Latent Dirichlet Allocation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
