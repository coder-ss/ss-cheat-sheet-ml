{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯决策论\n",
    "\n",
    "其实朴素贝叶斯已经看过好几遍了，但一直没有认真去看“贝叶斯决策论”（Bayesian decision theory）到底讲的是什么东西。可能看到了也觉得“不应该就是这样吗”、“这是很显而易见的呀”，直到这次决定对每个具体的点进行记录的时候，才仔细地阅读了“贝叶斯决策论”，它的核心思想就是选择具有较高概率的决策。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《机器学习实战》的描述\n",
    "\n",
    "《机器学习实战》对“贝叶斯决策论”进行了非常简单易懂的描述，摘录并稍作修改如下。\n",
    "\n",
    "对于数据集 $D=\\{(\\boldsymbol{x}_1, y_1), (\\boldsymbol{x}_2, y_2), \\ldots, (\\boldsymbol{x}_m, y_m)\\}$，每个样本 $\\boldsymbol{x} = (x_1, x_2, \\ldots, x_n)^T$ 有n个特征，y的取值范围为 $\\{0, 1\\}$，即这是一个二分类问题。$p(y=0 \\mid \\boldsymbol{x}_k)$ 表示样本 $\\boldsymbol{x}_k$ 属于类别0的概率，$p(y=1 \\mid \\boldsymbol{x}_k)$ 表示样本 $\\boldsymbol{x}_k$ 属于类别1的概率，可以用下面的规则来判断 $\\boldsymbol{x}_k$ 的类别：\n",
    "\n",
    "- 如果 $p(y=0 \\mid \\boldsymbol{x}_k) > p(y=1 \\mid \\boldsymbol{x}_k)$，那么类别为0\n",
    "- 如果 $p(y=1 \\mid \\boldsymbol{x}_k) > p(y=0 \\mid \\boldsymbol{x}_k)$，那么类别为1\n",
    "\n",
    "也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《机器学习》的描述\n",
    "\n",
    "周志华老师《机器学习》一书中对“贝叶斯决策论”进行了更细致的讲解，摘录如下。\n",
    "\n",
    "贝叶斯决策论是概率框架下实施决策的基本方法。对分类任务来说，在所有概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。下面我们以多分类任务为例来解释其基本原理。\n",
    "\n",
    "假设有N中可能的类别标记，即y的取值范围为 $\\mathcal{Y} = \\{c_1, c_2, \\ldots, c_N\\}$，$\\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本误分类为 $c_i$ 所产生的损失。基于后验概率 $P(c_i \\mid \\boldsymbol{x})$ 可获得将样本 $\\boldsymbol{x}$ 分类为 $c_i$ 所产生的期望损失（expected loss），即在样本 $\\boldsymbol{x} $ 上的条件风险（conditional risk）：\n",
    "\n",
    "$$ R(c_i \\mid \\boldsymbol{x}) = \\sum_{j=1}^{N} \\lambda_{ij} P(c_j \\mid \\boldsymbol{x}) $$\n",
    "\n",
    "我们的任务是寻找到一个判断准则 $h:\\ \\mathcal{X} \\mapsto \\mathcal{Y}$ 以最小化总体风险：\n",
    "\n",
    "$$ R(h) = \\mathbb{E}_{\\boldsymbol{x}} \\left[ R(h(\\boldsymbol{x} \\mid \\boldsymbol{x} ) \\right]$$\n",
    "\n",
    "显然，对每个样本，若h能最小化条件风险 $R(h(\\boldsymbol{x} \\mid \\boldsymbol{x} )$，则总体风险也将被最小化。这就产生了贝叶斯判定准则（Bayes decision rule）：为最小化总体风险，只需在每个样本上选择那个能使条件风险 $R(c \\mid \\boldsymbol{x}) $ 的类别标记，即\n",
    "\n",
    "$$ h^{*}(\\boldsymbol{x}) = \\underset{c \\in \\mathcal{Y}}{\\arg \\min} R(c \\mid \\boldsymbol{x}) $$\n",
    "\n",
    "这时，$h^*$ 称为贝叶斯最优分类器（Bayes optimal classifier），与之对应的总体风险 $R(h^*)$ 称为贝叶斯风险（Bayes risk）。$1-R(h^*)$ 反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。\n",
    "\n",
    "具体来说，若目标是最小化分类错误率，则误判损失函数 $\\lambda_{ij}$ 可写为\n",
    "\n",
    "$$ \\lambda_{ij} = \\left\\{ \\begin{aligned} 0 &, \\text{if}\\ i=j; \\\\ 1 &, \\text{otherwise} \\end{aligned} \\right. $$\n",
    "\n",
    "此时条件风险\n",
    "\n",
    "$$ R(c \\mid \\boldsymbol{x}) = 1 - P(c \\mid \\boldsymbol{x}) $$\n",
    "\n",
    "于是，最小化分类错误率的贝叶斯最优分类器为\n",
    "\n",
    "$$ h^*(\\boldsymbol{x}) = \\underset{c \\in \\mathcal{y}}{\\arg \\max}\\ P(c \\mid \\boldsymbol{x}) $$\n",
    "\n",
    "即对每个样本 $\\boldsymbol{x}$，选择能使后验概率 $P(c \\mid \\boldsymbol{x})$ 最大的类别标记。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于后验概率 $P(c \\mid \\boldsymbol{x})$ 的求解会在单独的一个速查手册“判别式与生成式”中详细论述。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
